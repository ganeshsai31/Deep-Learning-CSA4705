# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_diabetes
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ------------------------------------
# STEP 1: Load a numerical dataset
# ------------------------------------
data = load_diabetes()
X = data.data
y = data.target

print("Dataset Shape:", X.shape)
print("Feature Names:", data.feature_names)

# Create a DataFrame for better visualization
df = pd.DataFrame(X, columns=data.feature_names)
df['Target'] = y
print("\nSample Data:\n", df.head())

# ------------------------------------
# STEP 2: Split the data into train and test sets
# ------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# ------------------------------------
# STEP 3: Train the Linear Regression Model
# ------------------------------------
model = LinearRegression()
model.fit(X_train, y_train)

# ------------------------------------
# STEP 4: Predict the values
# ------------------------------------
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# ------------------------------------
# STEP 5: Evaluate Model Performance
# ------------------------------------
train_mse = mean_squared_error(y_train, y_train_pred)
test_mse = mean_squared_error(y_test, y_test_pred)
train_mae = mean_absolute_error(y_train, y_train_pred)
test_mae = mean_absolute_error(y_test, y_test_pred)
train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)

print("\n===== MODEL PERFORMANCE =====")
print(f"Training MSE: {train_mse:.2f}")
print(f"Testing MSE: {test_mse:.2f}")
print(f"Training MAE: {train_mae:.2f}")
print(f"Testing MAE: {test_mae:.2f}")
print(f"Training R²: {train_r2:.3f}")
print(f"Testing R²: {test_r2:.3f}")

# ------------------------------------
# STEP 6: Visualize Predictions vs Actual Values
# ------------------------------------
plt.figure(figsize=(7, 5))
plt.scatter(y_test, y_test_pred, color='blue', edgecolor='k')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.title("Linear Regression: Actual vs Predicted Values")
plt.xlabel("Actual Target Values")
plt.ylabel("Predicted Target Values")
plt.grid(True)
plt.show()

# ------------------------------------
# STEP 7: Visualize Error Distribution
# ------------------------------------
errors = y_test - y_test_pred
plt.figure(figsize=(7, 4))
plt.hist(errors, bins=20, color='skyblue', edgecolor='black')
plt.title("Error Distribution (Residuals)")
plt.xlabel("Prediction Error")
plt.ylabel("Frequency")
plt.show()

# ------------------------------------
# STEP 8: Display Regression Coefficients
# ------------------------------------
coef_df = pd.DataFrame({
    'Feature': data.feature_names,
    'Coefficient': model.coef_
})
print("\nRegression Coefficients:\n", coef_df)

# Visualization of Coefficients
plt.figure(figsize=(8, 5))
plt.barh(coef_df['Feature'], coef_df['Coefficient'], color='teal')
plt.title("Feature Importance (Linear Regression Coefficients)")
plt.xlabel("Coefficient Value")
plt.ylabel("Feature Name")
plt.show()
